(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{1280:function(s,n,a){s.exports=a.p+"assets/img/2019-06-214.26.25.01ad21cf.png"},1281:function(s,n,a){s.exports=a.p+"assets/img/2019-06-221.03.51.e07f3b7b.png"},1282:function(s,n,a){s.exports=a.p+"assets/img/2019-06-221.09.10.1b15352f.png"},1283:function(s,n,a){s.exports=a.p+"assets/img/2019-06-221.11.00.cb8b86a6.png"},1284:function(s,n,a){s.exports=a.p+"assets/img/2019-06-221.16.37.e81371fa.png"},1285:function(s,n,a){s.exports=a.p+"assets/img/2019-06-221.22.47.937d9e26.png"},1286:function(s,n,a){s.exports=a.p+"assets/img/2019-06-221.57.26.b7defdf9.png"},1287:function(s,n,a){s.exports=a.p+"assets/img/2019-06-221.46.12.8c2cc690.png"},1288:function(s,n,a){s.exports=a.p+"assets/img/2019-06-222.04.31.75121137.png"},1289:function(s,n,a){s.exports=a.p+"assets/img/2019-06-222.07.16.72c63cbb.png"},1290:function(s,n,a){s.exports=a.p+"assets/img/2019-06-222.12.03.9feb467b.png"},1291:function(s,n,a){s.exports=a.p+"assets/img/2019-06-222.15.12.ed3d7cc3.png"},1292:function(s,n,a){s.exports=a.p+"assets/img/linear.5bda2b4c.png"},2432:function(s,n,a){"use strict";a.r(n);var t=a(9),e=Object(t.a)({},(function(){var s=this,n=s.$createElement,t=s._self._c||n;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h3",{attrs:{id:"一-多元线性回归"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一-多元线性回归"}},[s._v("#")]),s._v(" "),t("code",[s._v("(一)多元线性回归")])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1280),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[t("p",[s._v("简单说明一下简单线性回归和多元线性回归问题")]),s._v(" "),t("ul",[t("li",[s._v("1：当$x_i$为一个特征时候，就是简单线性回归")]),s._v(" "),t("li",[s._v("2：当$x_i$为一组特征时候，那么$X_1^i$就是X矩阵的第i行第一个特征，$X_2^i$就是第i行的第二个特征, $X_3^i$就是第i行的第三个特征")]),s._v(" "),t("li",[s._v("3：那么之前的y = ax + b的简单线性回归问题，就变成了: y = $θ_0$ + $θ_1x_1$ + $θ_2x_2$ + $θ_3x_3$ + ... + $θ_nx_n$")]),s._v(" "),t("li",[s._v("4:  那么预测值：$y^i$ = $θ_0$ + $θ_1X_1^i$ + $θ_2X_2^i$ + $θ_3X_3^i$ + ... + $θ_nX_n^i$   ($X_1^i$就是X矩阵的第i行第一个特征)")])])]),s._v(" "),t("li",[t("p",[s._v("在简单线性回归和多元线性回归中都需要计算出参数，那么就是让下面这个式子尽可能的小")])])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1281),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("但是在多元线性回归中不再是y = ax + b，而是")])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1282),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[t("p",[s._v("所以在多元线性回归中，就需要找到 $θ_0$，$θ_1$，$θ_2$，..., $θ_n$ 使得\n"),t("img",{attrs:{src:a(1283),alt:"Alt text"}})])]),s._v(" "),t("li",[t("p",[s._v("可以将需要从训练数据中学习获得的$θ_0$，$θ_1$，$θ_2$，..., $θ_n$ 可用一个向量来表示：θ = $(θ_0,θ_1,θ_2,...,θ_n)^T$, θ是一个列向量")])]),s._v(" "),t("li",[t("p",[s._v("将多元线性回归进行整理， 虚构了一个$X_0^i$ 这个特征，表示第i行的第0个特征， 且 这里的 $X_0^i$ = 1")])])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1284),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("那么对于$X^i$就可以表示为如下矩阵，i表示矩阵的行号， 在这个矩阵中，每一行代表一个样本，每一列代表一个特征")])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1285),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("那么多元线性回归方程可以表示为：")])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1286),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("这是一个列向量")])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1287),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("那么问题转变为求θ向量，满足如下条件， 这个转置是将列向量转变为行向量，方便进行矩阵运算，最终计算出来的结果是一个数值")])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1288),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("那么问题再次转变为：")])]),s._v(" "),t("h2",{attrs:{id:""}},[t("a",{staticClass:"header-anchor",attrs:{href:"#"}},[s._v("#")]),s._v(" "),t("img",{attrs:{src:a(1289),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("这里同样使用的是**"),t("code",[s._v("最小二乘法")]),s._v("**对整个矩阵就行求导求极值的运算，推导出来的结果如下，这个结果在网上可以查到，也可以自己推导（这是多元线性回归的正规方程解）")])]),s._v(" "),t("p",[t("img",{attrs:{src:a(1290),alt:"Alt text"}})]),s._v(" "),t("ul",[t("li",[s._v("运算的时间复杂度")])]),s._v(" "),t("h2",{attrs:{id:"-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#-2"}},[s._v("#")]),s._v(" "),t("img",{attrs:{src:a(1291),alt:"Alt text"}})]),s._v(" "),t("h3",{attrs:{id:"二-使用多元线性回归算法预测房价-且评测准确度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二-使用多元线性回归算法预测房价-且评测准确度"}},[s._v("#")]),s._v(" "),t("code",[s._v("(二)使用多元线性回归算法预测房价，且评测准确度")])]),s._v(" "),t("ul",[t("li",[s._v("自实现的LinearRegression算法")])]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("import numpy as np\nfrom metrics import r2_score\n\nclass LinearRegression:\n    def __init__(self):\n        # 这是系数\n        self.coef_ = None\n        # 这个是截距\n        self.interception_ = None\n        # 这个就是具体计算出来的θ列向量\n        self._theta = None\n\n    # 这里的拟合是使用正规方程求解\n    def fit_normal(self, X_train, y_train):\n        assert X_train.shape[0] == y_train.shape[0], \\\n        '训练数据集必须与预测训练一个维度'\n\n        # 构建特征矩阵， np.ones((X_train.shape[0], 1)), 为元素都为1的矩阵，且只有1列\n        X_b = np.hstack([\n                         np.ones((X_train.shape[0], 1)),\n                         X_train,\n                        ])\n\n        # 使用θ表达式，计算出θ的值\n        self._theta = np.linalg.inv(X_b.T.dot(X_b))\\\n                      .dot(X_b.T)\\\n                      .dot(y_train)\n\n        # 那么截距就是第一个元素\n        self.interception_ = self._theta[0]\n        # 系数就是后面的元素\n        self.coef_ = self._theta[1:]\n\n        return self\n\n    # 预测\n    def predict(self, X_predict):\n\n        assert self.interception_ is not None and self.coef_ is not None, \\\n        '必须先调用fit_normal方法'\n\n        assert X_predict.shape[1] == len(self.coef_), \\\n        '被预测矩阵的列数必须与系数向量的长度相等'\n\n        # 通过传递进来的X_predict计算新的矩阵X_b\n        X_b = np.hstack([\n            np.ones((X_predict.shape[0], 1)),\n            X_predict,\n        ])\n\n        return X_b.dot(self._theta)\n\n    # 使用R Squared 评测算法，评测算法的准确度\n    def score(self, X_test, y_test):\n        y_predict = self.predict(X_test)\n        return r2_score(y_test, y_predict)\n\n    def __str__(self):\n        return \"LinearRegression(coef_={}, \" \\\n               \"interception_={}, \" \\\n               \"_theta={})\".format(self.coef_, self.interception_, self._theta)\n\n    __repr__ = __str__\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br")])]),t("ul",[t("li",[s._v("使用自己实现的LinearRegression算法")])]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n\n# 加载波士顿房产数据\nboston = datasets.load_boston()\n\nX = boston.data\ny = boston.target\n\n# 这里使用的是fancing indexing的方式过滤数据\nX = X[y < 50.0]\ny = y[y < 50.0]\n\n# 分离训练数据和测试数据\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)\n\n# 导入自实现的LinearRegression类\nfrom linearRegression import LinearRegression\n\nreg = LinearRegression()\nreg.fit_normal(X_train, y_train)\n\n# 查看预测精确度\nreg.score(X_test, y_test)\n输出结果：\n0.8009390227580956\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br")])]),t("ul",[t("li",[s._v("使用scikit-learn的LinearRegression算法")])]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("import numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n\n# 加载波士顿房产数据\nboston = datasets.load_boston()\n\nX = boston.data\ny = boston.target\n\n# 这里使用的是fancing indexing的方式过滤数据\nX = X[y < 50.0]\ny = y[y < 50.0]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)\n\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\nlin_reg.score(X_test, y_test)\n输出结果：\n0.8009390227581041\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br")])]),t("ul",[t("li",[s._v("使用使用kNN Regressor类解决线性回归问题（这里说明了kNN也可以解决回归问题）")])]),s._v(" "),t("h4",{attrs:{id:"没有搜索超参数的情况下"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#没有搜索超参数的情况下"}},[s._v("#")]),s._v(" 没有搜索超参数的情况下")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("from sklearn.neighbors import KNeighborsRegressor\nknn_reg = KNeighborsRegressor()\nknn_reg.fit(X_train, y_train)\nknn_reg.score(X_test, y_test)\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("h4",{attrs:{id:"搜索超参数的情况下"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#搜索超参数的情况下"}},[s._v("#")]),s._v(" 搜索超参数的情况下")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # 这是第一组的网格搜索\n    {\n        'weights': ['uniform'],\n         'n_neighbors': [i for i in range(1, 11)],\n    },\n    \n    # 这是第二组的网格搜索\n    {\n        'weights': ['distance'],\n        'n_neighbors': [i for i in range(1, 11)],\n        'p': [i for i in range(1,6)],\n    }\n]\n\nknn_reg = KNeighborsRegressor()\ngrid_search = GridSearchCV(knn_reg, param_grid, n_jobs=-1, verbose=2, cv=3)\ngrid_search.fit(X_train, y_train)\n\ngrid_search.best_params_\n输出结果：\n{'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n\ngrid_search.best_score_\n输出结果：\n0.6060528490355778\n\ngrid_search.best_estimator_.score(X_test, y_test)\n输出结果：\n0.7353138117643773\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br")])]),t("h3",{attrs:{id:"三-线性回归中的可解释性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#三-线性回归中的可解释性"}},[s._v("#")]),s._v(" "),t("code",[s._v("(三)线性回归中的可解释性")])]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X,y)\nprint(lin_reg.coef_)\n输出结果：\n[-1.06715912e-01  3.53133180e-02 -4.38830943e-02  4.52209315e-01\n -1.23981083e+01  3.75945346e+00 -2.36790549e-02 -1.21096549e+00\n  2.51301879e-01 -1.37774382e-02 -8.38180086e-01  7.85316354e-03\n -3.50107918e-01]\n \n # 将系数进行排序，值越小表示房价越低\nnp.argsort(lin_reg.coef_)\n输出结果：\narray([ 4,  7, 10, 12,  0,  2,  6,  9, 11,  1,  8,  3,  5])\n\n# 原特征矩阵\nprint(boston.feature_names)\n输出结果：\n['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n 'B' 'LSTAT']\nprint('~'*100)\n# 排序后的特征矩阵\nprint(boston.feature_names[np.argsort(lin_reg.coef_)])\n输出结果：\n['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n 'B' 'LSTAT']\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n['NOX' 'DIS' 'PTRATIO' 'LSTAT' 'CRIM' 'INDUS' 'AGE' 'TAX' 'B' 'ZN' 'RAD'\n 'CHAS' 'RM']\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br")])]),t("ul",[t("li",[s._v("小结：")])]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("正相关\nRM:表示是房间的数量 \nCHAS：表示房子临河面\n\n负相关\nNOX: 表示：房子一氧化氮溶度 \nDIS: 距离劳务中心的距离\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("p",[t("img",{attrs:{src:a(1292),alt:"Alt text"}})])])}),[],!1,null,null,null);n.default=e.exports}}]);