(window.webpackJsonp=window.webpackJsonp||[]).push([[112],{1799:function(a,s,n){a.exports=n.p+"assets/img/2021-02-069.38.59.7abad04c.png"},1800:function(a,s,n){a.exports=n.p+"assets/img/2021-02-069.56.26.83dbb713.png"},1801:function(a,s,n){a.exports=n.p+"assets/img/2021-02-0610.22.59.80e6c6c9.png"},1802:function(a,s,n){a.exports=n.p+"assets/img/2021-02-0712.25.16.7bbee213.png"},1803:function(a,s,n){a.exports=n.p+"assets/img/2021-02-0712.26.07.1ede5761.png"},2706:function(a,s,n){"use strict";n.r(s);var e=n(9),t=Object(e.a)({},(function(){var a=this,s=a.$createElement,e=a._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h2",{attrs:{id:"一-consumer-group-rebalance-成员加入和退出组的过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一-consumer-group-rebalance-成员加入和退出组的过程"}},[a._v("#")]),a._v(" 一：Consumer Group Rebalance 成员加入和退出组的过程")]),a._v(" "),e("h3",{attrs:{id:"一-consumer-group-rebalance"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一-consumer-group-rebalance"}},[a._v("#")]),a._v(" （一）Consumer Group Rebalance")]),a._v(" "),e("ul",[e("li",[a._v("Partition 与 Consumer直接的关系（由如下分析可知，partition等于consumer最好）")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("1：如果partition数大于consumer，那么一个consumer将负载多个partition的数据消费\n2：如果partition等于consumer，那么一个consumer将负载一个partition的数据消费\n3：如果partition小于consumer，那么多余的consumer将会消费不到数据，导致consumer浪费\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("ul",[e("li",[a._v("新成员加入Kafka，消费组的Coordinator进行Rebalance的过程")])]),a._v(" "),e("p",[e("img",{attrs:{src:n(1799),alt:"Alt text"}})]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("coordinator: 消费组中的协调者，用于协调partition与consumer之间的关系\n\n对上图的简要解释：当有consumer加入到kafka消费组时候，coordinator会将组内的所有consumer都与partition断开，然后让所有的consumer重新连接(包括新加入的consumer)，根据partition的个数，重新给consumer分配可连接的partition\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("ul",[e("li",[a._v("成员退出Kafka，消费组的Coordinator进行Rebalance的过程")])]),a._v(" "),e("p",[e("img",{attrs:{src:n(1800),alt:"Alt text"}})]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("对上图的简要解释：当有consumer从kafka消费组退出时候，coordinator会将组内的所有consumer都与partition断开，然后让所有的consumer重新连接(包括新加入的consumer)，根据partition的个数，重新给consumer分配可连接的partition\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br")])]),e("ul",[e("li",[a._v("consumer提交offset（提交失败，会造成重复消费）")])]),a._v(" "),e("p",[e("img",{attrs:{src:n(1801),alt:"Alt text"}})]),a._v(" "),e("h2",{attrs:{id:"二-kafka集群"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#二-kafka集群"}},[a._v("#")]),a._v(" 二：Kafka集群")]),a._v(" "),e("h3",{attrs:{id:"一-kafka节点故障"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一-kafka节点故障"}},[a._v("#")]),a._v(" （一）Kafka节点故障")]),a._v(" "),e("ul",[e("li",[e("p",[a._v("Kafka与Zookeeper心跳未保持，此时集群认为此节点故障")])]),a._v(" "),e("li",[e("p",[a._v("Follower消息落后于Leader太多，此时集群认为此节点故障")])]),a._v(" "),e("li",[e("p",[a._v("Kafka会对故障节点进行移除")])])]),a._v(" "),e("h3",{attrs:{id:"二-kafka对故障节点的处理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#二-kafka对故障节点的处理"}},[a._v("#")]),a._v(" （二）Kafka对故障节点的处理")]),a._v(" "),e("ul",[e("li",[e("p",[a._v("Kafka集群不会因为节点故障，丢失数据")])]),a._v(" "),e("li",[e("p",[a._v("Kafka的语义担保避免了数据的丢失")])]),a._v(" "),e("li",[e("p",[a._v("Kafka会对消息进行集群内部平衡，减少消息在某个broker上热度过高")])])]),a._v(" "),e("h3",{attrs:{id:"三-kafka中leader选举-可以认为是选举partition的leader"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#三-kafka中leader选举-可以认为是选举partition的leader"}},[a._v("#")]),a._v(" （三）Kafka中Leader选举(可以认为是选举partition的leader)")]),a._v(" "),e("ul",[e("li",[e("p",[a._v("Kafka会维护一组Leader数据的副本(isr)")])]),a._v(" "),e("li",[e("p",[a._v("Kafka会在isr中选择一个速度比较快的Leader")])])]),a._v(" "),e("h3",{attrs:{id:"四-kafka集群中-不保证消息的有序性"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#四-kafka集群中-不保证消息的有序性"}},[a._v("#")]),a._v(" （四）Kafka集群中，不保证消息的有序性")]),a._v(" "),e("ul",[e("li",[a._v("为什么我们将Kafka作为日志的消息中间件的时候，日志写入到ES后是有序的呢")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("\t因为logstash从kafka获取数据，是从Leader partition中读取数据的，那么这种情况下，有序消费的速度非常快，使得kafka一有数据就会被消费，那么这样就不会造成ES中写入数据是无序的情况。但是实际上，Topic中不同的leader partition数据是并列的，这是kafka集群中多leader partition的特性\n\t\n\t因此，如果业务场景中，必须保证消息的有序性，应该使用rabbitmq\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("h2",{attrs:{id:"三-kafka集群配置文件优化"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#三-kafka集群配置文件优化"}},[a._v("#")]),a._v(" 三：Kafka集群配置文件优化")]),a._v(" "),e("h3",{attrs:{id:"一-kafka节点故障-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一-kafka节点故障-2"}},[a._v("#")]),a._v(" （一）Kafka节点故障")]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("# id可以从1开始，当然也可以是从0开始\nbroker.id=1\n# 监听的IP地址\nlisteners=PLAINTEXT://192.168.100.246:9092\n# 这个是borker进行网络处理的线程数，为CPU和核心数\nnum.network.threads=32\n# 这个是borker进行I/O处理的线程数\nnum.io.threads=20\n# 发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能\nsocket.send.buffer.bytes=102400\n# kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘\nsocket.receive.buffer.bytes=102400\n# 这个参数是向kafka请求消息或向kafka发送消息最大字节数，这个值不能超过java的堆栈大小\nsocket.request.max.bytes=104857600\n# 数据目录不会放在/tmp目录下\nlog.dirs=/tmp/kafka-logs\n# 默认一个topic的partitions为5\nnum.partitions=5\n# 日志恢复的线程数\nnum.recovery.threads.per.data.dir=1\n# 默认的partition副本集为2, 至少为2\ndefault.replication.factor=2\n# kafka内部默认的__consumer_offsets，partition默认是50，这是是设置其partition的副本数\noffsets.topic.replication.factor=2\n# 事务主题的复制因子\ntransaction.state.log.replication.factor=1\n# 覆盖事务主题的min.insync.replicas配置, 意思是isr中有一个可用的partition即可提交\ntransaction.state.log.min.isr=1\n# 默认消息的最大持久化时间，168小时，7天，可以改为1天\nlog.retention.hours=168\n# 这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件\nlog.segment.bytes=1073741824\n# 每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除\nlog.retention.check.interval.ms=300000\n# zookeeper地址\nzookeeper.connect=192.168.100.246:2181,192.168.100.180:2181,192.168.100.200:2181\n# zookeeper连接超时\nzookeeper.connection.timeout.ms=18000\n# 在实际使用时，假设你预估你的所有consumer组成员加入需要在10s内完成，那么你就可以设置该参数=10000\n# 如果你发现消费者无法加入集群，那么可以修改这个值\ngroup.initial.rebalance.delay.ms=10000\n# 不允许topic被自动创建\nauto.create.topics.enable=false\n# 是否允许删除topic\ndelete.topic.enable=true\n# 消费者定期向broker发送心跳，如果超过这个时间，消费组就会将其消费的partition分配给其他消费者\ngroup.min.session.timeout.ms=6000\ngroup.max.session.timeout.ms=3000000\n# kafka异常终止时，允许自动同步数，默认是true\n# controlled.shutdown.enable=true\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br"),e("span",{staticClass:"line-number"},[a._v("11")]),e("br"),e("span",{staticClass:"line-number"},[a._v("12")]),e("br"),e("span",{staticClass:"line-number"},[a._v("13")]),e("br"),e("span",{staticClass:"line-number"},[a._v("14")]),e("br"),e("span",{staticClass:"line-number"},[a._v("15")]),e("br"),e("span",{staticClass:"line-number"},[a._v("16")]),e("br"),e("span",{staticClass:"line-number"},[a._v("17")]),e("br"),e("span",{staticClass:"line-number"},[a._v("18")]),e("br"),e("span",{staticClass:"line-number"},[a._v("19")]),e("br"),e("span",{staticClass:"line-number"},[a._v("20")]),e("br"),e("span",{staticClass:"line-number"},[a._v("21")]),e("br"),e("span",{staticClass:"line-number"},[a._v("22")]),e("br"),e("span",{staticClass:"line-number"},[a._v("23")]),e("br"),e("span",{staticClass:"line-number"},[a._v("24")]),e("br"),e("span",{staticClass:"line-number"},[a._v("25")]),e("br"),e("span",{staticClass:"line-number"},[a._v("26")]),e("br"),e("span",{staticClass:"line-number"},[a._v("27")]),e("br"),e("span",{staticClass:"line-number"},[a._v("28")]),e("br"),e("span",{staticClass:"line-number"},[a._v("29")]),e("br"),e("span",{staticClass:"line-number"},[a._v("30")]),e("br"),e("span",{staticClass:"line-number"},[a._v("31")]),e("br"),e("span",{staticClass:"line-number"},[a._v("32")]),e("br"),e("span",{staticClass:"line-number"},[a._v("33")]),e("br"),e("span",{staticClass:"line-number"},[a._v("34")]),e("br"),e("span",{staticClass:"line-number"},[a._v("35")]),e("br"),e("span",{staticClass:"line-number"},[a._v("36")]),e("br"),e("span",{staticClass:"line-number"},[a._v("37")]),e("br"),e("span",{staticClass:"line-number"},[a._v("38")]),e("br"),e("span",{staticClass:"line-number"},[a._v("39")]),e("br"),e("span",{staticClass:"line-number"},[a._v("40")]),e("br"),e("span",{staticClass:"line-number"},[a._v("41")]),e("br"),e("span",{staticClass:"line-number"},[a._v("42")]),e("br"),e("span",{staticClass:"line-number"},[a._v("43")]),e("br"),e("span",{staticClass:"line-number"},[a._v("44")]),e("br"),e("span",{staticClass:"line-number"},[a._v("45")]),e("br"),e("span",{staticClass:"line-number"},[a._v("46")]),e("br"),e("span",{staticClass:"line-number"},[a._v("47")]),e("br"),e("span",{staticClass:"line-number"},[a._v("48")]),e("br"),e("span",{staticClass:"line-number"},[a._v("49")]),e("br"),e("span",{staticClass:"line-number"},[a._v("50")]),e("br")])]),e("h2",{attrs:{id:"四-kafka的相关问题"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#四-kafka的相关问题"}},[a._v("#")]),a._v(" 四：Kafka的相关问题")]),a._v(" "),e("ul",[e("li",[a._v("为什么Kafka的速度快、吞吐量大")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("1：多个leader partition，提高了生产和消费速度\n2：partition写入到磁盘的时候，使用的是顺序读写，不是随机读写，因此使得写入数据非常快\n3：通过sendfile实现数据的零拷贝\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("h3",{attrs:{id:"一-kafka通过sendfile实现数据的零拷贝分析"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一-kafka通过sendfile实现数据的零拷贝分析"}},[a._v("#")]),a._v(" （一）kafka通过sendfile实现数据的零拷贝分析")]),a._v(" "),e("ul",[e("li",[a._v("传统的数据拷贝过程")])]),a._v(" "),e("p",[e("img",{attrs:{src:n(1802),alt:"Alt text"}})]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("一个应用程序需要从磁盘将数据发送到网卡，需要完成如下步骤：\n1：数据从磁盘被读取到内核缓冲区\n2：数据从内核缓冲区读取到用户缓冲区\n3：应用程序从用户缓冲区读取数据进行处理\n4：将应用程序处理完成的数据再次发送到用户缓冲区\n5：再从用户缓冲区发送到socket缓冲区\n6：再从socket缓冲区将数据发送到网卡\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br")])]),e("ul",[e("li",[a._v("sendfile数据零拷贝过程")])]),a._v(" "),e("p",[e("img",{attrs:{src:n(1803),alt:"Alt text"}})]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("sendfile零拷贝可以直接将数据从内核缓冲区发送到网卡：\n1：数据从磁盘被读取到内核缓冲区\n2：数据从内核缓冲区取到网卡\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br")])]),e("h3",{attrs:{id:"二-kafka的isr机制"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#二-kafka的isr机制"}},[a._v("#")]),a._v(" （二）Kafka的isr机制")]),a._v(" "),e("ul",[e("li",[a._v("什么是Kafka的isr机制")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("kafka的ISR机制被成为“不丢消息”机制\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br")])]),e("ul",[e("li",[a._v("isr机制如何做到partition之间的数据同步")])]),a._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("Kafka不是完全同步，也不是完全异步，是一种特殊的ISR（In Sync Replica）\n\t1：Leader Partition会维持一个与其保持同步的replica集合，该集合就是isr。每一个partition都有一个ISR，它时有leader动态维护\n\n\t2：我们要保证kafka不丢失message，就要保证isr这组集合存活（至少有一个存活），并且消息commit成功。\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br")])])])}),[],!1,null,null,null);s.default=t.exports}}]);